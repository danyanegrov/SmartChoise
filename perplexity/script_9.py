# –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–µ–∫—Ç–æ—Ä–æ–≤

data_loader_content = '''#!/usr/bin/env python3
"""
Data loader script for Intelligent Choice System
Loads sample data and generates embeddings for vector search
"""

import asyncio
import json
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import psycopg2
from pymilvus import connections, Collection, utility
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database configuration
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'choice_db',
    'user': 'postgres',
    'password': 'password'
}

# Milvus configuration
MILVUS_CONFIG = {
    'host': 'localhost',
    'port': 19530
}

class DataLoader:
    def __init__(self):
        self.embedder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.db_conn = None
        self.milvus_collection = None
    
    def connect_databases(self):
        """Connect to PostgreSQL and Milvus"""
        try:
            # Connect to PostgreSQL
            self.db_conn = psycopg2.connect(**DB_CONFIG)
            logger.info("Connected to PostgreSQL")
            
            # Connect to Milvus
            connections.connect(
                alias="default",
                host=MILVUS_CONFIG['host'],
                port=MILVUS_CONFIG['port']
            )
            
            # Get Milvus collection
            if utility.has_collection("item_embeddings"):
                self.milvus_collection = Collection("item_embeddings")
                logger.info("Connected to Milvus collection")
            else:
                logger.warning("Milvus collection 'item_embeddings' not found")
            
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            raise
    
    def load_additional_items(self):
        """Load more sample items into database"""
        additional_items = [
            # –ë–æ–ª—å—à–µ –Ω–æ—É—Ç–±—É–∫–æ–≤
            {
                'name': 'Dell XPS 13',
                'description': '–£–ª—å—Ç—Ä–∞–±—É–∫ —Å –±–µ–∑—Ä–∞–º–æ—á–Ω—ã–º –¥–∏—Å–ø–ª–µ–µ–º –∏ –¥–æ–ª–≥–æ–π –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å—é',
                'category_id': 2,
                'price': 79999,
                'rating': 4.4,
                'rating_count': 156,
                'attributes': '{"brand": "Dell", "processor": "Intel i7", "ram": "16GB", "storage": "512GB", "display": "13.3\\"}'
            },
            {
                'name': 'Acer Aspire 5',
                'description': '–ë—é–¥–∂–µ—Ç–Ω—ã–π –Ω–æ—É—Ç–±—É–∫ –¥–ª—è —É—á–µ–±—ã –∏ —Ä–∞–±–æ—Ç—ã',
                'category_id': 2,
                'price': 38999,
                'rating': 3.9,
                'rating_count': 89,
                'attributes': '{"brand": "Acer", "processor": "AMD Ryzen 5", "ram": "8GB", "storage": "256GB"}'
            },
            {
                'name': 'Microsoft Surface Laptop',
                'description': '–°—Ç–∏–ª—å–Ω—ã–π –Ω–æ—É—Ç–±—É–∫ —Å —Å–µ–Ω—Å–æ—Ä–Ω—ã–º —ç–∫—Ä–∞–Ω–æ–º',
                'category_id': 2,
                'price': 94999,
                'rating': 4.3,
                'rating_count': 134,
                'attributes': '{"brand": "Microsoft", "processor": "Intel i5", "ram": "8GB", "storage": "256GB", "touchscreen": true}'
            },
            
            # –ë–æ–ª—å—à–µ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–æ–≤
            {
                'name': 'OnePlus 11',
                'description': '–§–ª–∞–≥–º–∞–Ω—Å–∫–∏–π —Å–º–∞—Ä—Ç—Ñ–æ–Ω —Å –±—ã—Å—Ç—Ä–æ–π –∑–∞—Ä—è–¥–∫–æ–π',
                'category_id': 3,
                'price': 54999,
                'rating': 4.5,
                'rating_count': 267,
                'attributes': '{"brand": "OnePlus", "display": "6.7", "storage": "128GB", "camera": "50MP", "charging": "100W"}'
            },
            {
                'name': 'Huawei P60 Pro',
                'description': '–ö–∞–º–µ—Ä–æ—Ñ–æ–Ω —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å—ä–µ–º–∫–æ–π',
                'category_id': 3,
                'price': 67999,
                'rating': 4.4,
                'rating_count': 178,
                'attributes': '{"brand": "Huawei", "display": "6.67", "storage": "256GB", "camera": "48MP", "zoom": "5x"}'
            },
            {
                'name': 'Nothing Phone 2',
                'description': '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω —Å Glyph-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º',
                'category_id': 3,
                'price': 45999,
                'rating': 4.1,
                'rating_count': 92,
                'attributes': '{"brand": "Nothing", "display": "6.7", "storage": "128GB", "camera": "50MP", "glyph": true}'
            },
            
            # –ü–ª–∞–Ω—à–µ—Ç—ã (–Ω–æ–≤–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è)
            {
                'name': 'iPad Air',
                'description': '–ú–æ—â–Ω—ã–π –ø–ª–∞–Ω—à–µ—Ç –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞ –∏ —Ä–∞–±–æ—Ç—ã',
                'category_id': 1,
                'price': 59999,
                'rating': 4.6,
                'rating_count': 234,
                'attributes': '{"brand": "Apple", "display": "10.9", "storage": "64GB", "processor": "M1"}'
            },
            {
                'name': 'Samsung Galaxy Tab S8',
                'description': 'Android –ø–ª–∞–Ω—à–µ—Ç —Å S Pen –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ',
                'category_id': 1,
                'price': 49999,
                'rating': 4.3,
                'rating_count': 156,
                'attributes': '{"brand": "Samsung", "display": "11", "storage": "128GB", "s_pen": true}'
            },
            
            # –ë–æ–ª—å—à–µ –∫–Ω–∏–≥
            {
                'name': '–ê–ª–≥–æ—Ä–∏—Ç–º—ã: –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑',
                'description': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —É—á–µ–±–Ω–∏–∫ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º',
                'category_id': 7,
                'price': 3499,
                'rating': 4.8,
                'rating_count': 445,
                'attributes': '{"author": "–ö–æ—Ä–º–µ–Ω, –õ–µ–π–∑–µ—Ä—Å–æ–Ω, –†–∏–≤–µ—Å—Ç", "pages": 1296, "genre": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞"}'
            },
            {
                'name': '–ß–∏—Å—Ç—ã–π –∫–æ–¥',
                'description': '–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –Ω–∞–ø–∏—Å–∞–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞',
                'category_id': 7,
                'price': 2299,
                'rating': 4.7,
                'rating_count': 678,
                'attributes': '{"author": "–†–æ–±–µ—Ä—Ç –ú–∞—Ä—Ç–∏–Ω", "pages": 464, "genre": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"}'
            },
            {
                'name': '–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ',
                'description': '–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é',
                'category_id': 7,
                'price': 4199,
                'rating': 4.6,
                'rating_count': 234,
                'attributes': '{"author": "–¢–æ–º –ú–∏—Ç—á–µ–ª–ª", "pages": 432, "genre": "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"}'
            }
        ]
        
        try:
            cursor = self.db_conn.cursor()
            
            for item in additional_items:
                cursor.execute("""
                    INSERT INTO items (name, description, category_id, price, rating, rating_count, attributes)
                    VALUES (%(name)s, %(description)s, %(category_id)s, %(price)s, %(rating)s, %(rating_count)s, %(attributes)s)
                    ON CONFLICT (name) DO NOTHING
                """, item)
            
            self.db_conn.commit()
            logger.info(f"Loaded {len(additional_items)} additional items")
            
        except Exception as e:
            logger.error(f"Failed to load additional items: {e}")
            self.db_conn.rollback()
    
    def generate_embeddings(self):
        """Generate embeddings for all items and load into Milvus"""
        try:
            cursor = self.db_conn.cursor()
            
            # Get all items
            cursor.execute("""
                SELECT id, name, description, price, rating, 
                       c.name as category_name, attributes
                FROM items i
                LEFT JOIN categories c ON i.category_id = c.id
                WHERE i.is_available = true
            """)
            
            items = cursor.fetchall()
            logger.info(f"Found {len(items)} items to process")
            
            if not items:
                logger.warning("No items found in database")
                return
            
            # Prepare data for Milvus
            ids = []
            item_ids = []
            names = []
            categories = []
            embeddings = []
            metadata = []
            
            for item in items:
                item_id, name, description, price, rating, category_name, attributes = item
                
                # Create text for embedding
                text_parts = [name]
                if description:
                    text_parts.append(description)
                if category_name:
                    text_parts.append(category_name)
                
                text_for_embedding = " ".join(text_parts)
                
                # Generate embedding
                embedding = self.embedder.encode(text_for_embedding)
                
                # Prepare data
                ids.append(len(ids))  # Auto-increment ID for Milvus
                item_ids.append(item_id)
                names.append(name[:200])  # Truncate to fit VARCHAR limit
                categories.append(category_name[:100] if category_name else "")
                embeddings.append(embedding.tolist())
                
                # Create metadata
                item_metadata = {
                    "price": price,
                    "rating": float(rating) if rating else 0.0,
                    "attributes": json.loads(attributes) if attributes else {}
                }
                metadata.append(json.dumps(item_metadata, ensure_ascii=False)[:1000])
            
            # Insert into Milvus
            if self.milvus_collection and embeddings:
                # Clear existing data
                self.milvus_collection.delete("id >= 0")
                self.milvus_collection.flush()
                
                # Insert new data
                entities = [ids, item_ids, names, categories, embeddings, metadata]
                insert_result = self.milvus_collection.insert(entities)
                
                # Flush to make data searchable
                self.milvus_collection.flush()
                
                logger.info(f"Inserted {len(embeddings)} embeddings into Milvus")
                
                # Create index if not exists
                if not self.milvus_collection.has_index():
                    index_params = {
                        "metric_type": "COSINE",
                        "index_type": "HNSW",
                        "params": {"M": 16, "efConstruction": 200}
                    }
                    self.milvus_collection.create_index("embedding", index_params)
                    logger.info("Created index on embeddings")
                
                # Load collection
                self.milvus_collection.load()
                logger.info("Collection loaded and ready for search")
            
        except Exception as e:
            logger.error(f"Failed to generate embeddings: {e}")
            raise
    
    def create_sample_interactions(self):
        """Create more sample user interactions"""
        interactions = [
            # User 2 (testuser) interactions
            (2, 1, 'view', None, None),  # MacBook Air
            (2, 1, 'like', 5, '–û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'),
            (2, 2, 'view', None, None),  # ThinkPad
            (2, 2, 'like', 4, '–•–æ—Ä–æ—à–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞'),
            (2, 5, 'purchase', 5, '–ö—É–ø–∏–ª, –æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω'),  # iPhone
            
            # User 3 (alice) interactions  
            (3, 9, 'view', None, None),   # Python –∫–Ω–∏–≥–∞
            (3, 9, 'purchase', 5, '–û—Ç–ª–∏—á–Ω—ã–π —É—á–µ–±–Ω–∏–∫'),
            (3, 10, 'view', None, None),  # –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä
            (3, 10, 'like', 5, '–õ—é–±–∏–º–∞—è –∫–Ω–∏–≥–∞ –¥–µ—Ç—Å—Ç–≤–∞'),
            (3, 11, 'view', None, None),  # –ú–∞—Å—Ç–µ—Ä –∏ –ú–∞—Ä–≥–∞—Ä–∏—Ç–∞
            (3, 11, 'like', 4, '–ö–ª–∞—Å—Å–∏–∫–∞ —Ä—É—Å—Å–∫–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã'),
            
            # User 4 (bob) interactions
            (4, 13, 'view', None, None),  # Toyota
            (4, 13, 'like', 4, '–ù–∞–¥–µ–∂–Ω—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å'),
            (4, 14, 'view', None, None),  # BMW
            (4, 14, 'like', 5, '–û—Ç–ª–∏—á–Ω–∞—è —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç—å'),
            (4, 15, 'view', None, None),  # Tesla
            (4, 15, 'dislike', 2, '–°–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ'),
            (4, 3, 'view', None, None),   # ASUS ROG
            (4, 3, 'like', 5, '–ú–æ—â–Ω—ã–π –∏–≥—Ä–æ–≤–æ–π –Ω–æ—É—Ç–±—É–∫')
        ]
        
        try:
            cursor = self.db_conn.cursor()
            
            for interaction in interactions:
                user_id, item_id, int_type, rating, feedback = interaction
                cursor.execute("""
                    INSERT INTO user_interactions (user_id, item_id, interaction_type, rating, feedback)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT DO NOTHING
                """, (user_id, item_id, int_type, rating, feedback))
            
            self.db_conn.commit()
            logger.info(f"Created {len(interactions)} sample interactions")
            
        except Exception as e:
            logger.error(f"Failed to create interactions: {e}")
            self.db_conn.rollback()
    
    def run(self):
        """Run the full data loading process"""
        logger.info("Starting data loading process...")
        
        try:
            # Connect to databases
            self.connect_databases()
            
            # Load additional items
            self.load_additional_items()
            
            # Generate embeddings
            if self.milvus_collection:
                self.generate_embeddings()
            else:
                logger.warning("Skipping embedding generation - Milvus collection not available")
            
            # Create sample interactions
            self.create_sample_interactions()
            
            logger.info("Data loading completed successfully!")
            
        except Exception as e:
            logger.error(f"Data loading failed: {e}")
            raise
        
        finally:
            # Close connections
            if self.db_conn:
                self.db_conn.close()
                logger.info("Closed database connection")

def main():
    loader = DataLoader()
    loader.run()

if __name__ == "__main__":
    main()
'''

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
test_main_content = '''import pytest
import requests
import json
from app.services.nlp_service import nlp_processor
from app.services.recommendation_service import recommendation_engine

class TestAPI:
    """Integration tests for API endpoints"""
    
    BASE_URL = "http://localhost:8000/api/v1"
    
    def test_health_check(self):
        """Test health check endpoint"""
        response = requests.get(f"{self.BASE_URL}/health")
        assert response.status_code == 200
        
        data = response.json()
        assert "status" in data
        assert "services" in data
    
    def test_nlp_processing(self):
        """Test NLP processing endpoint"""
        payload = {
            "text": "–•–æ—á—É –∫—É–ø–∏—Ç—å –∏–≥—Ä–æ–≤–æ–π –Ω–æ—É—Ç–±—É–∫ –¥–æ 100000 —Ä—É–±–ª–µ–π",
            "user_context": {}
        }
        
        response = requests.post(f"{self.BASE_URL}/nlp/process", json=payload)
        assert response.status_code == 200
        
        data = response.json()
        assert "intent" in data
        assert "entities" in data
        assert "embedding" in data
        assert data["intent"] == "purchase"
    
    def test_recommendations(self):
        """Test recommendations endpoint"""
        payload = {
            "query": "–ü–æ—Å–æ–≤–µ—Ç—É–π —Ö–æ—Ä–æ—à–∏–π –Ω–æ—É—Ç–±—É–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã",
            "filters": {"max_price": 80000},
            "limit": 5
        }
        
        response = requests.post(f"{self.BASE_URL}/recommendations", json=payload)
        assert response.status_code == 200
        
        data = response.json()
        assert "recommendations" in data
        assert "intent" in data
        assert "processing_time_ms" in data
        assert len(data["recommendations"]) <= 5

class TestNLP:
    """Unit tests for NLP components"""
    
    def test_text_cleaning(self):
        """Test text preprocessing"""
        text = "–•–æ—á—É –∫—É–ø–∏—Ç—å –ù–û–£–¢–ë–£–ö –¥–ª—è —Ä–∞–±–æ—Ç—ã!!!"
        cleaned = nlp_processor._clean_text(text)
        
        assert cleaned.islower()
        assert "–Ω–æ—É—Ç–±—É–∫" in cleaned
        assert "!!!" not in cleaned
    
    def test_intent_classification(self):
        """Test intent classification"""
        test_cases = [
            ("–•–æ—á—É –∫—É–ø–∏—Ç—å –Ω–æ—É—Ç–±—É–∫", "purchase"),
            ("–°—Ä–∞–≤–Ω–∏ iPhone –∏ Samsung", "compare"),
            ("–ü–æ—Å–æ–≤–µ—Ç—É–π —Ö–æ—Ä–æ—à–∏–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω", "recommend"),
            ("–ù–∞–π–¥–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—å", "search")
        ]
        
        for text, expected_intent in test_cases:
            intent, confidence = nlp_processor._classify_intent(text)
            assert intent == expected_intent
            assert confidence > 0
    
    def test_entity_extraction(self):
        """Test entity extraction"""
        text = "–ù–æ—É—Ç–±—É–∫ –¥–æ 50000 —Ä—É–±–ª–µ–π –≤ –ú–æ—Å–∫–≤–µ"
        doc = nlp_processor.nlp(text)
        entities = nlp_processor._extract_entities(doc)
        
        # Should find price and location entities
        entity_texts = [e["text"] for e in entities]
        assert any("50000" in text for text in entity_texts)

class TestRecommendations:
    """Unit tests for recommendation engine"""
    
    @pytest.mark.asyncio
    async def test_recommendation_generation(self):
        """Test recommendation generation"""
        recommendations = await recommendation_engine.get_recommendations(
            user_id=None,
            query="–∏–≥—Ä–æ–≤–æ–π –Ω–æ—É—Ç–±—É–∫",
            filters={"max_price": 100000},
            limit=3
        )
        
        assert "recommendations" in recommendations
        assert "intent" in recommendations
        assert "processing_time_ms" in recommendations
        assert len(recommendations["recommendations"]) <= 3

if __name__ == "__main__":
    pytest.main([__file__])
'''

# README.md
readme_content = '''# –°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞

–°–∏—Å—Ç–µ–º–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –ø–æ–º–æ—â–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –≤ –ø—Ä–∏–Ω—è—Ç–∏–∏ —Ä–µ—à–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –∏ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.

## üöÄ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- üß† **NLP –æ–±—Ä–∞–±–æ—Ç–∫–∞** —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- ü§ñ **–ì–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ + –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
- üîç **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫** —á–µ—Ä–µ–∑ Milvus
- üìä **Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- üê≥ **Docker** –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
- üìà **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞** –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

### Backend
- **FastAPI** - REST API
- **PostgreSQL** - –æ—Å–Ω–æ–≤–Ω–∞—è –ë–î
- **Milvus** - –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î
- **Redis** - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ

### ML/NLP
- **sentence-transformers** - —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- **spaCy** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —è–∑—ã–∫–∞
- **transformers** - –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
- **scikit-learn** - ML –∞–ª–≥–æ—Ä–∏—Ç–º—ã

### Frontend
- **Streamlit** - –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **Plotly** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫

### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Docker –∏ Docker Compose
- Python 3.11+
- Git

### –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫

1. **–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–µ—Ä–µ—Ö–æ–¥ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é:**
```bash
git clone <repository-url>
cd intelligent-choice-system
```

2. **–ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker Compose:**
```bash
docker-compose up --build
```

3. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤:**
- API: http://localhost:8000
- Docs: http://localhost:8000/docs
- Frontend: http://localhost:8501
- Milvus: http://localhost:9091

### –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

1. **–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\\Scripts\\activate     # Windows
```

2. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:**
```bash
pip install -r requirements.txt
python -m spacy download ru_core_news_sm
```

3. **–ó–∞–ø—É—Å–∫ –ë–î —á–µ—Ä–µ–∑ Docker:**
```bash
docker-compose up postgres redis milvus etcd minio
```

4. **–ó–∞–ø—É—Å–∫ API:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

5. **–ó–∞–ø—É—Å–∫ Frontend:**
```bash
cd frontend
streamlit run app.py
```

## üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:

```bash
python data/load_data.py
```

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ PostgreSQL
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
- –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ Milvus
- –°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install pytest pytest-asyncio

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
pytest tests/ -v

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest tests/ --cov=app --cov-report=html
```

## üìö API –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ –∞–¥—Ä–µ—Å–∞–º:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### –û—Å–Ω–æ–≤–Ω—ã–µ endpoints:

- `POST /api/v1/recommendations` - –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- `POST /api/v1/nlp/process` - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
- `GET /api/v1/items` - –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤
- `POST /api/v1/recommendations/feedback` - –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
- `GET /api/v1/health` - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:

```python
import requests

response = requests.post("http://localhost:8000/api/v1/recommendations", json={
    "query": "–•–æ—á—É –∫—É–ø–∏—Ç—å –∏–≥—Ä–æ–≤–æ–π –Ω–æ—É—Ç–±—É–∫ –¥–æ 100000 —Ä—É–±–ª–µ–π",
    "filters": {
        "category": "laptops",
        "max_price": 100000
    },
    "limit": 5
})

recommendations = response.json()
```

### –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ NLP:

```python
response = requests.post("http://localhost:8000/api/v1/nlp/process", json={
    "text": "–ü–æ—Å–æ–≤–µ—Ç—É–π —Ö–æ—Ä–æ—à–∏–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω –≤ –ú–æ—Å–∫–≤–µ",
    "user_context": {}
})

nlp_result = response.json()
# nlp_result["intent"] == "recommend"
# nlp_result["entities"] —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ `.env` —Ñ–∞–π–ª–µ:

```env
DATABASE_URL=postgresql://postgres:password@localhost:5432/choice_db
REDIS_URL=redis://localhost:6379/0
MILVUS_HOST=localhost
MILVUS_PORT=19530
SECRET_KEY=your-secret-key
LOG_LEVEL=INFO
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–°–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:
- Health check endpoints
- –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

## ü§ñ –ê–ª–≥–æ—Ä–∏—Ç–º—ã

### –ì–∏–±—Ä–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:
- **40%** - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ)
- **35%** - –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è (–ø–æ—Ö–æ–∂–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏)
- **25%** - –ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è (–∞—Ç—Ä–∏–±—É—Ç—ã —Ç–æ–≤–∞—Ä–æ–≤)

### NLP Pipeline:
1. –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
2. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
3. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π
4. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
6. –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

## üêõ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º—ã —Å Docker:
```bash
# –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
docker-compose down
docker-compose up --build --force-recreate

# –û—á–∏—Å—Ç–∫–∞ Docker
docker system prune -a
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å Milvus:
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
curl http://localhost:9091/health

# –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
python -c "
from pymilvus import utility, connections
connections.connect()
utility.drop_collection('item_embeddings')
"
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å PostgreSQL:
```bash
# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
docker exec -it <postgres_container> psql -U postgres -d choice_db

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü
\\dt
```

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - —Å–º. —Ñ–∞–π–ª LICENSE

## üë• –£—á–∞—Å—Ç–∏–µ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature –≤–µ—Ç–∫—É
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –î–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã
5. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü–æ –≤–æ–ø—Ä–æ—Å–∞–º –∏ –ø—Ä–æ–±–ª–µ–º–∞–º —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ Issues –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.
'''

# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã
os.makedirs("tests", exist_ok=True)

with open("data/load_data.py", "w", encoding="utf-8") as f:
    f.write(data_loader_content)

with open("tests/__init__.py", "w") as f:
    f.write("")

with open("tests/test_main.py", "w", encoding="utf-8") as f:
    f.write(test_main_content)

with open("README.md", "w", encoding="utf-8") as f:
    f.write(readme_content)

print("‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
print("- data/load_data.py (—Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö)")
print("- tests/test_main.py (—Ç–µ—Å—Ç—ã)")
print("- README.md (–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)")

# –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª .env –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
env_content = '''# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/choice_db

# Redis
REDIS_URL=redis://localhost:6379/0

# Milvus
MILVUS_HOST=localhost
MILVUS_PORT=19530

# Security
SECRET_KEY=your-super-secret-key-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# API
API_V1_PREFIX=/api/v1

# ML Models
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
SPACY_MODEL=ru_core_news_sm

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
'''

with open(".env.example", "w", encoding="utf-8") as f:
    f.write(env_content)

print("- .env.example (–ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)")
print("\n" + "="*60)
print("üéâ –í–°–ï –§–ê–ô–õ–´ –ü–†–û–ï–ö–¢–ê –°–û–ó–î–ê–ù–´ –£–°–ü–ï–®–ù–û!")
print("="*60)